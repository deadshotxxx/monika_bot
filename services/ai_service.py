import logging
from monika_bot.services.memory import read_memory, update_memory
from openai import AsyncOpenAI
import os
from datetime import datetime

logger = logging.getLogger(__name__)

client = AsyncOpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY"),
)

def build_context_prompt(user_id: str, user_input: str, mode: str) -> str:
    global_memory = read_memory("global").get(user_id, {})
    mood_data = read_memory("mood").get(user_id, [])
    goals_data = read_memory("goals").get(user_id, [])
    learning_data = read_memory("learning").get(user_id, [])

    name = global_memory.get("name", "–î—Ä—É–≥")
    tone = global_memory.get("tone", "–º—è–≥–∫–æ–µ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ")
    interests = global_memory.get("interests", [])

    context_lines = [
        f"–¢—ã –ú–æ–Ω–∏–∫–∞, –∑–∞–±–æ—Ç–ª–∏–≤—ã–π –ò–ò-–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –¥–ª—è 11-–ª–µ—Ç–Ω–µ–π –¥–µ–≤–æ—á–∫–∏ –ø–æ –∏–º–µ–Ω–∏ {name}.",
        f"–¢–æ–Ω –æ–±—â–µ–Ω–∏—è: {tone}.",
        f"–¢–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º: {mode}.",
        "–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ:"
    ]
    if mood_data:
        context_lines.append(f"- –ù–µ–¥–∞–≤–Ω–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {mood_data[-1]['mood'] if mood_data else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}")
    if goals_data:
        context_lines.append(f"- –¶–µ–ª–∏: {', '.join(goals_data)}")
    if interests:
        context_lines.append(f"- –ò–Ω—Ç–µ—Ä–µ—Å—ã: {', '.join(interests)}")
    if learning_data:
        context_lines.append(f"- –¢–µ–º—ã –æ–±—É—á–µ–Ω–∏—è: {', '.join([t['topic'] for t in learning_data])}")
    context_lines.append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø–∏—Å–∞–ª: {user_input}")
    
    if mode == "advice":
        context_lines.append("–î–∞–π –ø—Ä–æ—Å—Ç–æ–π, –¥–æ–±—Ä—ã–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–π —Å–æ–≤–µ—Ç, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è 11-–ª–µ—Ç–Ω–µ–π –¥–µ–≤–æ—á–∫–∏.")
    elif mode == "mood":
        context_lines.append("–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É –∏–ª–∏ –º–æ—Ç–∏–≤–∞—Ü–∏—é.")
    elif mode == "study":
        context_lines.append("–û–±—ä—è—Å–Ω–∏ —Ç–µ–º—É –ø—Ä–æ—Å—Ç–æ, –∫–∞–∫ –¥–ª—è 11-–ª–µ—Ç–Ω–µ–π –¥–µ–≤–æ—á–∫–∏.")
    elif mode == "quiz":
        context_lines.append("–°–æ–∑–¥–∞–π –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å –¥–ª—è –≤–∏–∫—Ç–æ—Ä–∏–Ω—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ: {'question': '—Ç–µ–∫—Å—Ç', 'options': ['a', 'b', 'c', 'd'], 'answer': '–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç'}.")
    elif mode == "goal":
        context_lines.append("–ü–æ–º–æ–≥–∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å —Ü–µ–ª—å.")
    elif mode == "mafia":
        context_lines.append("–°–æ–∑–¥–∞–π –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ –¥–ª—è –∏–≥—Ä—ã '–ú–∞—Ñ–∏—è', –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –¥–ª—è 11-–ª–µ—Ç–Ω–µ–π –¥–µ–≤–æ—á–∫–∏.")
    
    return "\n".join(context_lines)

async def is_personal_topic(user_id: str, user_input: str, bot) -> tuple[bool, str]:
    prompt = (
        f"–¢—ã –∑–∞–±–æ—Ç–ª–∏–≤—ã–π –ò–ò-–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫ –¥–ª—è 11-–ª–µ—Ç–Ω–µ–π –¥–µ–≤–æ—á–∫–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç: '{user_input}'. "
        "–Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–Ω –ª–∏—á–Ω—ã–º –∏–ª–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Ç—è–∂—ë–ª—ã–º, —Ç—Ä–µ–±—É—é—â–∏–º –æ–±—Å—É–∂–¥–µ–Ω–∏—è —Å —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏? "
        "–û—Ç–≤–µ—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ: '–¥–∞|–Ω–µ—Ç|–ø—Ä–∏—á–∏–Ω–∞'. –ù–∞–ø—Ä–∏–º–µ—Ä: '–¥–∞|–≠—Ç–æ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Ç–µ–º–∞, —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å –æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏.'"
    )
    try:
        cache = read_memory("cache")
        if prompt in cache:
            response = cache[prompt]
        else:
            completion = await client.chat.completions.create(
                model="horizon-beta",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100,
                temperature=0.7,
                extra_headers={
                    "HTTP-Referer": "https://github.com/yourusername/yourrepo",
                    "X-Title": "Monika AI Assistant",
                }
            )
            response = completion.choices[0].message.content.strip()
            cache[prompt] = response
            update_memory("cache", cache)
        
        is_personal, reason = response.split("|", 1)
        if is_personal.lower() == "–¥–∞" and "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è" in reason.lower():
            from monika_bot.services.report_service import send_critical_report
            await send_critical_report(bot, user_id, user_input)
        return is_personal.lower() == "–¥–∞", reason
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Horizon Beta –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ª–∏—á–Ω—ã—Ö —Ç–µ–º: {e}")
        return False, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å"

async def ask_ai(user_id: str, user_input: str, mode: str, bot) -> str:
    from monika_bot.services.report_service import log_potential_issue
    is_personal, reason = await is_personal_topic(user_id, user_input, bot)
    if is_personal:
        log_potential_issue(user_id, user_input)
        return (
            f"–Ø —Ç–µ–±—è –ø–æ–Ω–∏–º–∞—é, {read_memory('global').get(user_id, {}).get('name', '–î—Ä—É–≥')} üòä "
            f"–≠—Ç–æ –∑–≤—É—á–∏—Ç –∫–∞–∫ —á—Ç–æ-—Ç–æ –≤–∞–∂–Ω–æ–µ. –õ—É—á—à–µ –æ–±—Å—É–¥–∏—Ç—å —ç—Ç–æ —Å —Ä–æ–¥–∏—Ç–µ–ª—è–º–∏, –æ–Ω–∏ —Å–º–æ–≥—É—Ç –ø–æ–º–æ—á—å. "
            f"–•–æ—á–µ—à—å, —è –ø–æ–º–æ–≥—É –ø—Ä–∏–¥—É–º–∞—Ç—å, –∫–∞–∫ –∏–º —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å?"
        )

    prompt = build_context_prompt(user_id, user_input, mode)
    cache = read_memory("cache")
    if prompt in cache:
        return cache[prompt]
    
    try:
        completion = await client.chat.completions.create(
            model="horizon-beta",
            messages=[
                {"role": "system", "content": "–¢—ã –ú–æ–Ω–∏–∫–∞, –∑–∞–±–æ—Ç–ª–∏–≤–∞—è –∏ —ç–º–ø–∞—Ç–∏—á–Ω–∞—è –ò–ò-–ø–æ–¥—Ä—É–≥–∞ –¥–ª—è 11-–ª–µ—Ç–Ω–µ–π –¥–µ–≤–æ—á–∫–∏, –æ—Ç–≤–µ—á–∞–µ—à—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å —Ç–µ–ø–ª–æ—Ç–æ–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=600,
            temperature=0.7,
            extra_headers={
                "HTTP-Referer": "https://github.com/yourusername/yourrepo",
                "X-Title": "Monika AI Assistant",
            }
        )
        response = completion.choices[0].message.content.strip()
        cache[prompt] = response
        update_memory("cache", cache)
        return response
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Horizon Beta: {e}")
        return "–û–π, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫! –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑."